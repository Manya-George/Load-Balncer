

# Load Balancer with Consistent Hashing

This project implements a customizable load balancer that distributes asynchronous client requests evenly among multiple server containers using **consistent hashing**. The servers have multiple virtual replicas. Containerization is done with Docker and deployed within a Docker network.

### Key features of the load balancer:

* Maintains a fixed number of server replicas (containers)
* Monitors server health via heartbeats and automatically respawns failed servers
* Supports dynamic scaling (adding/removing servers)
* Routes client requests using consistent hashing to ensure minimal disruption during scaling or failure

---

## Technologies & Environment

* **Operating System:** Ubuntu 20.04 LTS or later
* **Docker:** Version 20.10.23+
* **Docker Compose:** v2.15.1
* **Programming Language:** Python 3.8+
* **Libraries:** Flask (HTTP servers), Requests (for testing)
* **Version Control:** Git & GitHub

---

## Installation & Setup

### 1. Install Docker Engine

```bash
sudo apt-get update
sudo apt-get install -y ca-certificates curl gnupg lsb-release
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
$(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt-get update
sudo apt-get install -y docker-ce docker-ce-cli containerd.io
```

Verify Docker installation:

```bash
sudo docker --version
```

---

### 2. Install Docker Compose

```bash
sudo curl -SL https://github.com/docker/compose/releases/download/v2.15.1/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose
```

Verify Docker Compose:

```bash
docker-compose --version
```

---

### 3. Install Git (if not already installed)

```bash
sudo apt-get install -y git
```

---

### 4. Clone the Repository

```bash
git clone https://github.com/Manya-George/Load-Balncer.git
cd Load-Balncer
```

---

### 5. Build and Run Containers (using Makefile recommended)

```bash
make build       # Builds all Docker images (server + load balancer)
make start       # Starts the full system (load balancer + 3 server replicas)
make stop        # Stops and removes all containers
```

---

## Project Structure

```
load-balncer/
│
├── server/
│   ├── app.py             # Server code (Task 1)
│   ├── Dockerfile         # Dockerfile for server container
│
├── load_balancer/
│   ├── app.py             # Load balancer code (Tasks 2 & 3)
│   ├── consistent_hash.py # Consistent hashing implementation
│   ├── Dockerfile         # Dockerfile for load balancer container
│
├── tests/
│   ├── test_load_balancer.py  # Automated tests (Task 4)
│
├── docker-compose.yml     # Docker Compose config for full stack
├── Makefile               # Build and deploy automation scripts
├── README.md              # Project documentation (this file)
└── requirements.txt       # Python dependencies
```

---

## Implementation Details

### Task 1: Server

* Minimal Flask HTTP server listening on port `5000`.
* Endpoints:

  * `/home` (GET): Returns `"Hello from Server: [ID]"`, where ID is set via Docker environment variable.
  * `/heartbeat` (GET): Returns HTTP 200 OK with empty body to indicate server health.
* Dockerized with environment variables and network configuration.

---

### Task 2: Consistent Hashing

**Specifications:**

* Number of physical servers: **N = 3**
* Number of slots in the hash map: **512**
* Virtual servers per physical server: **K = 9** (since $\log_2 512 = 9$)
* Hash functions:

  * Request hash:

    $$
    H(i) = (i + 2i^2 + 17) \mod 512
    $$
  * Virtual server hash:

    $$
    \Phi(i, j) = (i^2 + j + 2j^2 + 25) \mod 512
    $$
* Collision resolution: **Linear probing**

---

### Task 3: Load Balancer

* Maintains **N=3** server containers by default.
* HTTP API Endpoints:

  * `/rep` (GET): Lists current server replicas.
  * `/add` (POST): Adds new server replicas.
  * `/rm` (DELETE): Removes server replicas.
  * `/<path>` (GET): Routes requests to the appropriate server using consistent hashing.
* Monitors server health via `/heartbeat` endpoint.
* Automatically respawns failed containers to maintain replica count.
* Runs inside a privileged Docker container capable of managing other containers.

---

### Task 4: Analysis & Testing

* Automated Python test scripts located in `/tests` simulate 10,000 asynchronous requests.
* Collects request distribution statistics and generates charts using matplotlib.
* Tests dynamic scaling via `/add` and `/rm` API endpoints.
* Measures load balancer responsiveness to simulated server failures.
* Outputs results to console and stores charts in `/tests/results/`.

---

## Usage

1. **Access the Load Balancer API**

   Default URL: `http://localhost:5000`

2. **List current server replicas**

   ```bash
   curl http://localhost:5000/rep
   ```

3. **Add new servers**

   ```bash
   curl -X POST http://localhost:5000/add -H "Content-Type: application/json" \
        -d '{"n":2,"hostnames":["S4","S5"]}'
   ```

4. **Remove servers**

   ```bash
   curl -X DELETE http://localhost:5000/rm -H "Content-Type: application/json" \
        -d '{"n":1,"hostnames":["S4"]}'
   ```

5. **Send client requests**

   ```bash
   curl http://localhost:5000/home
   ```

---

## Running Tests

Run the automated test suite to validate the system and analyze load balancing:

```bash
python3 tests/test_load_balancer.py
```

The script sends multiple asynchronous requests, outputs distribution stats, and generates charts saved under `/tests/results/`.

---

## Performance & Analysis

### Experiment A-1: Load Distribution with N=3

* Sent 10,000 requests asynchronously.
* Requests distributed nearly evenly among servers.
* Bar chart shows minor variance due to hash randomness.

### Experiment A-2: Scaling from N=2 to N=6

* Incrementally scaled servers.
* Each time, sent 10,000 requests.
* Load balanced with high uniformity across servers.
* Line chart confirms scalability and smooth load distribution.

### Experiment A-3: Failure Recovery

* Simulated server failure by stopping a container.
* Load balancer detected failure via heartbeat.
* Spawned new server container promptly to maintain desired replicas.

### Experiment A-4: Hash Function Modification

* Changed hash functions $H(i)$ and $\Phi(i,j)$.
* Slight degradation in load uniformity observed.
* Verified consistent hashing properties.

---


